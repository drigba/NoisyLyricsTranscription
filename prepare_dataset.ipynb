{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cf2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.openslr.org/resources/17/musan.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -zxvf musan.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b85d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MUSAN dataset\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "noise_ds = load_dataset('./musan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7416f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample MUSAN dataset to 44.1kHz\n",
    "import torchaudio.transforms as T\n",
    "def resample_audio(batch, new_freq):\n",
    "    audio_array = torch.FloatTensor(batch['audio']['array'])\n",
    "    original_sampling_rate = batch['audio']['sampling_rate']\n",
    "    \n",
    "    if original_sampling_rate != 16000:\n",
    "        raise ValueError(\"Expected original sampling rate to be 16kHz.\")\n",
    "    \n",
    "    resampler = T.Resample(orig_freq=16000, new_freq=new_freq)\n",
    "    resampled_audio = resampler(audio_array).squeeze().numpy()\n",
    "    \n",
    "    batch['audio']['array'] = resampled_audio\n",
    "    batch['audio']['sampling_rate'] = new_freq\n",
    "    return batch\n",
    "\n",
    "# Apply the resampling function to the dataset\n",
    "noise_ds = noise_ds['train'].map(resample_audio, new_freq=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load paired jar-alt dataset (train80 valid10 test10)\n",
    "dataset_p = load_dataset('audioshake/jam-alt', revision='v1.0.0')\n",
    "train_trainvalid_p = dataset_p['test'].train_test_split(test_size=0.2)\n",
    "\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid_p = train_trainvalid_p['test'].train_test_split(test_size=0.5)\n",
    "paired_ds = DatasetDict({\n",
    "    'train': train_trainvalid_p['train'],\n",
    "    'test': test_valid_p['test'],\n",
    "    'valid': test_valid_p['train']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b96f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise randomly to dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import torchaudio\n",
    "import soundfile\n",
    "\n",
    "def add_noise_to_audio(audio, noise, clean_db, noise_snr):\n",
    "    noise_db = 10 * np.log10(np.mean(noise ** 2)+1e-4) \n",
    "    noises = [np.sqrt(10 ** ((clean_db - noise_db - noise_snr) / 10)) * noise]\n",
    "\n",
    "    if len(noises[0]) < len(audio):\n",
    "        added = np.pad(noises[0], (0, len(audio)-len(noises[0])), 'constant') + audio\n",
    "    else:\n",
    "        added = audio + noises[0][:len(audio)]\n",
    " \n",
    "    return added\n",
    "\n",
    "\n",
    "def add_noise_to_dataset(batch, noise_dataset):#, noise_sample=None):\n",
    "    noise_sample = noise_dataset[random.randint(0, len(noise_dataset) - 1)]\n",
    "    noise_array = noise_sample['audio']['array'] * 30\n",
    "\n",
    "    audio_array = batch['audio']['array']\n",
    "    clean_db = 10 * np.log10(np.mean(audio_array ** 2)+1e-4) ##\n",
    "    audio_array = audio_array.squeeze()#.numpy()\n",
    "    \n",
    "    noisy_audio = add_noise_to_audio(audio_array, noise_array, clean_db, noise_snr=10)\n",
    "    \n",
    "    batch[\"audio\"] = noisy_audio\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5964c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = paired_ds.map(lambda batch: add_noise_to_dataset(batch, noise_ds['train']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
