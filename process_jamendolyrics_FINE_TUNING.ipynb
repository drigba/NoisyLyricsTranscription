{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ed9e11a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ed9e11a",
        "outputId": "7a47fb83-3823-427c-afbf-da72c85f9d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/542.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/542.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.5/289.5 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install datasets --quiet\n",
        "!pip install accelerate -U --quiet\n",
        "!pip install evaluate --quiet\n",
        "!pip install jiwer -U  -q\n",
        "!pip install transformers -U -q\n",
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1a85e70",
      "metadata": {
        "id": "b1a85e70"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/f90/jamendolyrics.git --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OhjulrrcPkKl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhjulrrcPkKl",
        "outputId": "a712aab9-0c48-409f-b63a-b66f898ee0b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=13bUduvbSf4AowpM5NN-owNKUYdQsrfm_\n",
            "From (redirected): https://drive.google.com/uc?id=13bUduvbSf4AowpM5NN-owNKUYdQsrfm_&confirm=t&uuid=032ea16f-0471-4c34-9fab-3c034cefa62b\n",
            "To: /content/musan_resampled.zip\n",
            "100% 1.61G/1.61G [00:24<00:00, 66.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 13bUduvbSf4AowpM5NN-owNKUYdQsrfm_\n",
        "!unzip -q /content/musan_resampled.zip\n",
        "!rm /content/musan_resampled.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LzuC3YKrkKcH",
      "metadata": {
        "collapsed": true,
        "id": "LzuC3YKrkKcH"
      },
      "outputs": [],
      "source": [
        "# !wget https://www.openslr.org/resources/17/musan.tar.gz\n",
        "# !tar -zxf musan.tar.gz\n",
        "# !rm -rf /content/musan/music\n",
        "# !rm -rf /content/musan/speech\n",
        "# !rm /content/musan.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sXpWUXwgBn2E",
      "metadata": {
        "id": "sXpWUXwgBn2E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import argparse\n",
        "import evaluate\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "from datasets import DatasetDict, Audio, load_from_disk, concatenate_datasets\n",
        "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
        "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n",
        "from datasets import load_dataset, DatasetDict\n",
        "import wandb\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torchaudio\n",
        "import soundfile\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "import pandas as pd\n",
        "import csv\n",
        "import librosa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VAfD3Cn8HQuc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAfD3Cn8HQuc",
        "outputId": "0fb82011-7fe4-4f47-a143-7bc1c619b428"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbanfizsombor1999\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GZhJijLABzUr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GZhJijLABzUr",
        "outputId": "e2778e06-0e74-465c-9c19-934a072c2afa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = \"openai/whisper-medium\"\n",
        "# LANGUAGE = \"en\"\n",
        "FREEZE_FEATURE_ENCODER = False\n",
        "FREEZE_ENCODER = False\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(MODEL_NAME)\n",
        "tokenizer = WhisperTokenizer.from_pretrained(MODEL_NAME,  task=\"transcribe\")\n",
        "processor = WhisperProcessor.from_pretrained(MODEL_NAME,task=\"transcribe\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hc0w1TYVKO4X",
      "metadata": {
        "id": "hc0w1TYVKO4X"
      },
      "outputs": [],
      "source": [
        "if FREEZE_FEATURE_ENCODER:\n",
        "    model.freeze_feature_encoder()\n",
        "\n",
        "if FREEZE_ENCODER:\n",
        "    model.freeze_encoder()\n",
        "    model.model.encoder.gradient_checkpointing = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DrAjL5bRMn26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "DrAjL5bRMn26",
        "outputId": "8922055a-b429-4dd5-bc95-26e966b73af1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"metadata\",\n  \"rows\": 79,\n  \"fields\": [\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 79,\n        \"samples\": [\n          \"https://www.jamendo.com/track/1870094/confession/lyrics\",\n          \"https://www.jamendo.com/track/1559261/give-me-the-same\",\n          \"https://www.jamendo.com/track/1246750/besando-sapos/lyrics\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Filepath\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 79,\n        \"samples\": [\n          \"Confession_-_Quesabe.mp3\",\n          \"HILA_-_Give_Me_the_Same.mp3\",\n          \"Besando_Sapos_-_Dream_Tabu.mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Artist\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          \"Avercage\",\n          \"WASARU\",\n          \"Pure Mids\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 79,\n        \"samples\": [\n          \"Confession\",\n          \"Give Me The Same\",\n          \"Besando Sapos\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Genre\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"Folk\",\n          \"Country\",\n          \"Pop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LicenseType\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"CC  BY-NC-SA\",\n          \"CC BY-SA\",\n          \"BY-ND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"German\",\n          \"French\",\n          \"English\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LyricOverlap\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polyphonic\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NonLexical\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "metadata"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f5a6d1dd-8935-45fc-b6c3-28edc85c46b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL</th>\n",
              "      <th>Filepath</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Title</th>\n",
              "      <th>Genre</th>\n",
              "      <th>LicenseType</th>\n",
              "      <th>Language</th>\n",
              "      <th>LyricOverlap</th>\n",
              "      <th>Polyphonic</th>\n",
              "      <th>NonLexical</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.jamendo.com/track/1559261/give-me-...</td>\n",
              "      <td>HILA_-_Give_Me_the_Same.mp3</td>\n",
              "      <td>HILA</td>\n",
              "      <td>Give Me The Same</td>\n",
              "      <td>Pop</td>\n",
              "      <td>BY-ND</td>\n",
              "      <td>English</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.jamendo.com/track/1552064/keep-on</td>\n",
              "      <td>Quentin_Hannappe_-_Keep_On.mp3</td>\n",
              "      <td>Quentin Hannappe</td>\n",
              "      <td>Keep On</td>\n",
              "      <td>Pop</td>\n",
              "      <td>BY-NC-ND</td>\n",
              "      <td>English</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.jamendo.com/track/1537288/back-in-...</td>\n",
              "      <td>Songwriterz_-_Back_In_Time.mp3</td>\n",
              "      <td>Songwriterz</td>\n",
              "      <td>Back In Time</td>\n",
              "      <td>Pop</td>\n",
              "      <td>BY-ND</td>\n",
              "      <td>English</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.jamendo.com/track/1442030/peyote</td>\n",
              "      <td>Kinematic_-_Peyote.mp3</td>\n",
              "      <td>KINEMATIC</td>\n",
              "      <td>Peyote</td>\n",
              "      <td>Rock</td>\n",
              "      <td>BY-ND</td>\n",
              "      <td>English</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.jamendo.com/track/1465148/embers</td>\n",
              "      <td>Avercage_-_Embers.mp3</td>\n",
              "      <td>Avercage</td>\n",
              "      <td>Embers</td>\n",
              "      <td>Rock</td>\n",
              "      <td>BY-NC-SA</td>\n",
              "      <td>English</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5a6d1dd-8935-45fc-b6c3-28edc85c46b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5a6d1dd-8935-45fc-b6c3-28edc85c46b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5a6d1dd-8935-45fc-b6c3-28edc85c46b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ca87f375-175d-45ab-998f-ce4c7f499e58\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca87f375-175d-45ab-998f-ce4c7f499e58')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ca87f375-175d-45ab-998f-ce4c7f499e58 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 URL  \\\n",
              "0  https://www.jamendo.com/track/1559261/give-me-...   \n",
              "1      https://www.jamendo.com/track/1552064/keep-on   \n",
              "2  https://www.jamendo.com/track/1537288/back-in-...   \n",
              "3       https://www.jamendo.com/track/1442030/peyote   \n",
              "4       https://www.jamendo.com/track/1465148/embers   \n",
              "\n",
              "                         Filepath            Artist             Title Genre  \\\n",
              "0     HILA_-_Give_Me_the_Same.mp3              HILA  Give Me The Same   Pop   \n",
              "1  Quentin_Hannappe_-_Keep_On.mp3  Quentin Hannappe           Keep On   Pop   \n",
              "2  Songwriterz_-_Back_In_Time.mp3       Songwriterz      Back In Time   Pop   \n",
              "3          Kinematic_-_Peyote.mp3         KINEMATIC            Peyote  Rock   \n",
              "4           Avercage_-_Embers.mp3          Avercage            Embers  Rock   \n",
              "\n",
              "  LicenseType Language  LyricOverlap  Polyphonic  NonLexical  \n",
              "0       BY-ND  English         False       False       False  \n",
              "1    BY-NC-ND  English         False       False       False  \n",
              "2       BY-ND  English         False       False        True  \n",
              "3       BY-ND  English         False        True       False  \n",
              "4    BY-NC-SA  English         False       False       False  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metadata = pd.read_csv('/content/jamendolyrics/JamendoLyrics.csv')\n",
        "metadata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W9sXRRa4M3ho",
      "metadata": {
        "id": "W9sXRRa4M3ho"
      },
      "outputs": [],
      "source": [
        "metadata = metadata.set_index(\"Filepath\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbc43dd3",
      "metadata": {
        "id": "cbc43dd3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "SR = 16000\n",
        "mp3_path = '/content/jamendolyrics/mp3/'\n",
        "csv_path = '/content/jamendolyrics/annotations/lines/'\n",
        "file_names = sorted(glob.glob(csv_path + '*.csv'))\n",
        "\n",
        "gather_n = 4 ################################################### Combine n data samples into one data\n",
        "len_files = []\n",
        "start_time = []\n",
        "end_time = []\n",
        "audio_types = []\n",
        "lyrics = []\n",
        "languages = []\n",
        "audio_dict = {} # load audio array in advance to use less RAM. key: 0~78, value: np.array\n",
        "\n",
        "for f in file_names:\n",
        "    c = pd.read_csv(f)\n",
        "    len_files.append(len(c))\n",
        "\n",
        "def preprocess_dataset():\n",
        "    for num, filename in enumerate(file_names):\n",
        "        len_csv = len_files[num]\n",
        "        with open(f\"{filename}\", \"r\") as f:\n",
        "            csv_data = csv.reader(f)\n",
        "            audio_name = filename.split('/')[-1][:-4] + '.mp3'\n",
        "            language = metadata.loc[audio_name][\"Language\"].lower()\n",
        "            processor.tokenizer.set_prefix_tokens(language=language)\n",
        "\n",
        "            for i, line in enumerate(csv_data):\n",
        "                if i== 0: # except first head\n",
        "                    continue\n",
        "\n",
        "                if gather_n == 1: # not combine samples\n",
        "                    st = float(line[0])\n",
        "                    et = float(line[1])\n",
        "                    lyric = line[2]\n",
        "                    lyric = processor.tokenizer(lyric).input_ids\n",
        "\n",
        "                    start_time.append(st)\n",
        "                    end_time.append(et)\n",
        "                    lyrics.append(lyric)\n",
        "                    audio_types.append(num)\n",
        "\n",
        "                else:\n",
        "                    if i%gather_n == 1: # start gathering frames\n",
        "                        st = float(line[0])\n",
        "                        et = float(line[1])\n",
        "                        lyric = line[2]\n",
        "\n",
        "                    else:\n",
        "                        et = float(line[1])\n",
        "                        lyric += (' ' + line[2])\n",
        "\n",
        "                    if i%gather_n == 0 or i == len_csv: # end of the group or the last line\n",
        "                        start_time.append(st)\n",
        "                        end_time.append(et)\n",
        "                        lyric = processor.tokenizer(lyric).input_ids\n",
        "                        lyrics.append(lyric)\n",
        "                        audio_types.append(num)\n",
        "\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86360ee4",
      "metadata": {
        "collapsed": true,
        "id": "86360ee4"
      },
      "outputs": [],
      "source": [
        "preprocess_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7ea96c2",
      "metadata": {
        "id": "f7ea96c2"
      },
      "outputs": [],
      "source": [
        "# Load original audio arrays in advance\n",
        "for i, filename in enumerate(file_names):\n",
        "    audio_name = filename.split('/')[-1][:-4] + '.mp3'\n",
        "    audio_dict[i], _ = librosa.load(mp3_path + audio_name, sr=SR)\n",
        "\n",
        "trimmed_audios = []\n",
        "def trim_audio(audio_name, st, et):\n",
        "    start_frame = SR*st\n",
        "    end_frame = SR*et\n",
        "    audio  = audio_dict[audio_name] # sr=44100\n",
        "    trimmed_audio = audio[int(start_frame):int(end_frame)+1]\n",
        "\n",
        "    return trimmed_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147f1351",
      "metadata": {
        "id": "147f1351"
      },
      "outputs": [],
      "source": [
        "for audio_type, st, et in zip(audio_types, start_time, end_time):\n",
        "    trimmed_audios.append(trim_audio(audio_type, st, et))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lD1sCie3j02I",
      "metadata": {
        "id": "lD1sCie3j02I"
      },
      "outputs": [],
      "source": [
        "# noise_ds = load_dataset('./musan')\n",
        "noise_ds = load_from_disk('/content/content/musan_resampled')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "umULLfHr55AH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "umULLfHr55AH",
        "outputId": "fbd9f7d7-4133-4f54-c896-b270bb88c096"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.03685588, -0.12578191,  0.02261727, ...,  0.18195425,\n",
              "        0.09405375,  0.03368825], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trimmed_audios[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cabf3f19",
      "metadata": {
        "id": "cabf3f19"
      },
      "outputs": [],
      "source": [
        "# Pytorch Dataset\n",
        "# Have to add noise before feature extraction\n",
        "\n",
        "\n",
        "def add_noise_to_audio(audio, noise, clean_db, noise_snr):\n",
        "    noise_db = 10 * np.log10(np.mean(noise ** 2)+1e-4)\n",
        "    noises = [np.sqrt(10 ** ((clean_db - noise_db - noise_snr) / 10)) * noise]\n",
        "\n",
        "    if len(noises[0]) < len(audio):\n",
        "        added = np.pad(noises[0], (0, len(audio)-len(noises[0])), 'constant') + audio\n",
        "    else:\n",
        "        added = audio + noises[0][:len(audio)]\n",
        "\n",
        "    return added\n",
        "\n",
        "class PairedDataset(Dataset):\n",
        "    def __init__(self, trimmed_audios, lyrics,noise_ds,snr = 10,random_augment = True):\n",
        "        self.lyrics = lyrics\n",
        "        self.trimmed_audios = trimmed_audios\n",
        "        self.noise_dataset = noise_ds\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.snr = snr\n",
        "\n",
        "        self.random_augment = random_augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lyrics)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.random_augment:\n",
        "          noise_index = random.randint(0, len(self.noise_dataset) - 1)\n",
        "        else:\n",
        "          noise_index = index % len(self.noise_dataset)\n",
        "\n",
        "        noise_sample = self.noise_dataset[noise_index]\n",
        "        noise_array = noise_sample['audio']['array'] * 30\n",
        "        audio_array = self.trimmed_audios[index]\n",
        "\n",
        "        clean_db = 10 * np.log10(np.mean(audio_array ** 2)+1e-4) ##\n",
        "        audio_array = audio_array.squeeze()#.numpy()\n",
        "        noisy_audio = add_noise_to_audio(audio_array, noise_array, clean_db, noise_snr=self.snr)\n",
        "\n",
        "        audio_processed = self.feature_extractor(noisy_audio, sampling_rate=SR).input_features[0]\n",
        "\n",
        "        return {'input_features': audio_processed, 'labels': self.lyrics[index]}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48288eb8",
      "metadata": {
        "id": "48288eb8"
      },
      "outputs": [],
      "source": [
        "SNR = -3\n",
        "paired_dataset = PairedDataset(trimmed_audios, lyrics, noise_ds,snr = SNR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "072d475f",
      "metadata": {
        "id": "072d475f"
      },
      "source": [
        "### Approach 1. Use pytorch dataset format (I'm not sure if this format is also available in huggingface Trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d72369",
      "metadata": {
        "id": "48d72369"
      },
      "outputs": [],
      "source": [
        "### Approach 1. Use pytorch dataset format (I'm not sure if this format is also available in huggingface Trainer)\n",
        "\n",
        "import torch\n",
        "from torch.utils.data.dataset import random_split\n",
        "len_full_dataset = len(paired_dataset)\n",
        "\n",
        "# train samples\n",
        "train_p = 0.8\n",
        "len_train = int(len_full_dataset * train_p)\n",
        "\n",
        "# valid samples\n",
        "valid_p = 0.1\n",
        "len_valid = int(len_full_dataset * 0.1)\n",
        "\n",
        "train_dataset, valid_dataset = random_split(paired_dataset, [len_train, len_full_dataset-len_train])\n",
        "valid_dataset, test_dataset = random_split(valid_dataset, [len_valid, len(valid_dataset)-len_valid])\n",
        "\n",
        "train_dataset.random_augment = True\n",
        "valid_dataset.random_augment = False\n",
        "test_dataset.random_augment = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fda7d1ab",
      "metadata": {
        "id": "fda7d1ab"
      },
      "outputs": [],
      "source": [
        "# # Check if the audio aligns with text well\n",
        "# import IPython.display as ipd\n",
        "# idx = 20\n",
        "# print(train_dataset[idx]['labels'])\n",
        "# ipd.Audio(train_dataset[idx]['input_features'], rate=44100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TGlE7CG5vsrT",
      "metadata": {
        "id": "TGlE7CG5vsrT"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\", padding=True)\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uibPFbArvy23",
      "metadata": {
        "id": "uibPFbArvy23"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0EmVp_4wOQgQ",
      "metadata": {
        "id": "0EmVp_4wOQgQ"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"wer\")\n",
        "DO_NORMALIZE_EVAL = True\n",
        "normalizer = BasicTextNormalizer()\n",
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    if DO_NORMALIZE_EVAL:\n",
        "        pred_str = [normalizer(pred) for pred in pred_str]\n",
        "        label_str = [normalizer(label) for label in label_str]\n",
        "\n",
        "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "    return {\"wer\": wer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FKZ9X2YeW5-H",
      "metadata": {
        "id": "FKZ9X2YeW5-H"
      },
      "outputs": [],
      "source": [
        "from transformers.integrations import WandbCallback\n",
        "\n",
        "\n",
        "def decode_predictions(tokenizer, predictions):\n",
        "    pred_ids = predictions.predictions\n",
        "    label_ids = predictions.label_ids\n",
        "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    return {\"labels\": label_str, \"predictions\": pred_str}\n",
        "\n",
        "\n",
        "class WandbPredictionProgressCallback(WandbCallback):\n",
        "    \"\"\"Custom WandbCallback to log model predictions during training.\n",
        "\n",
        "    This callback logs model predictions and labels to a wandb.Table at each logging step during training.\n",
        "    It allows to visualize the model predictions as the training progresses.\n",
        "\n",
        "    Attributes:\n",
        "        trainer (Trainer): The Hugging Face Trainer instance.\n",
        "        tokenizer (AutoTokenizer): The tokenizer associated with the model.\n",
        "        sample_dataset (Dataset): A subset of the validation dataset for generating predictions.\n",
        "        num_samples (int, optional): Number of samples to select from the validation dataset for generating predictions. Defaults to 100.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, trainer, tokenizer, val_dataset, num_samples=100, freq=2):\n",
        "        \"\"\"Initializes the WandbPredictionProgressCallback instance.\n",
        "\n",
        "        Args:\n",
        "            trainer (Trainer): The Hugging Face Trainer instance.\n",
        "            tokenizer (AutoTokenizer): The tokenizer associated with the model.\n",
        "            val_dataset (Dataset): The validation dataset.\n",
        "            num_samples (int, optional): Number of samples to select from the validation dataset for generating predictions. Defaults to 100.\n",
        "            freq (int, optional): Control the frequency of logging. Defaults to 2.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.trainer = trainer\n",
        "        self.tokenizer = tokenizer\n",
        "        noise_indexes = random.sample(range(0, len(val_dataset)-1), num_samples)\n",
        "        self.sample_dataset = [val_dataset[noise_index] for noise_index in noise_indexes]\n",
        "        self.freq = freq\n",
        "\n",
        "\n",
        "    def on_evaluate(self, args, state, control,  **kwargs):\n",
        "        super().on_evaluate(args, state, control, **kwargs)\n",
        "        # control the frequency of logging by logging the predictions every `freq` epochs\n",
        "        if state.epoch % self.freq == 0:\n",
        "            # generate predictions\n",
        "            predictions = self.trainer.predict(self.sample_dataset)\n",
        "            # decode predictions and labels\n",
        "            predictions = decode_predictions(self.tokenizer, predictions)\n",
        "            # add predictions to a wandb.Table\n",
        "            predictions_df = pd.DataFrame(predictions)\n",
        "            predictions_df[\"epoch\"] = state.epoch\n",
        "\n",
        "            # get audio samples from sample_dataset\n",
        "\n",
        "            # add audio samples as a new column to the DataFrame\n",
        "\n",
        "            records_table = self._wandb.Table(dataframe=predictions_df)\n",
        "            # log the table to wandb\n",
        "            self._wandb.log({\"sample_predictions\": records_table})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cMP7tAIFDLL",
      "metadata": {
        "id": "8cMP7tAIFDLL"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_PROJECT\"] = \"Noisy Lyrics Transcription\"  # name your W&B project\n",
        "os.environ[\"ENTITY\"] = \"gct634\"  # name your W&B project\n",
        "\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"end\"\n",
        "\n",
        "# turn off watch to log faster\n",
        "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u4w-6iurbUFg",
      "metadata": {
        "id": "u4w-6iurbUFg"
      },
      "outputs": [],
      "source": [
        "OUTPUT_DIR = \"whisper-medium-finetuned-jamendo-snr-3\"\n",
        "TRAIN_BATCHSIZE = 32\n",
        "LEARNING_RATE = 1e-5\n",
        "WARMUP = 5\n",
        "EVAL_BATCHSIZE = 5\n",
        "RESUME_FROM_CKPT = None\n",
        "NUM_EPOCHS = 50\n",
        "GRADIENT_CHECKPOINTING= True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "th7u1JFBFQut",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th7u1JFBFQut",
        "outputId": "fc5287fb-eadb-4c08-e773-4b2e57fc680b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir= OUTPUT_DIR,\n",
        "        per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
        "        gradient_accumulation_steps=1,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        warmup_steps=WARMUP,\n",
        "        gradient_checkpointing=GRADIENT_CHECKPOINTING,\n",
        "        fp16=True,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=2,\n",
        "        load_best_model_at_end = True,\n",
        "        num_train_epochs=NUM_EPOCHS,\n",
        "        per_device_eval_batch_size=EVAL_BATCHSIZE,\n",
        "        predict_with_generate=True,\n",
        "        generation_max_length=225,\n",
        "        logging_strategy='epoch',\n",
        "        report_to=[\"wandb\"],\n",
        "        metric_for_best_model=\"wer\",\n",
        "        greater_is_better=False,\n",
        "        optim=\"adamw_hf\",\n",
        "        resume_from_checkpoint=RESUME_FROM_CKPT,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-bN3ajlV5eLz",
      "metadata": {
        "id": "-bN3ajlV5eLz"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TxjCKRfh9Rx2",
      "metadata": {
        "id": "TxjCKRfh9Rx2"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStoppingCallback(early_stopping_patience=10)\n",
        "progress_callback = WandbPredictionProgressCallback(trainer, processor.tokenizer, valid_dataset, 10,1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "babNyipE9TZv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "babNyipE9TZv",
        "outputId": "77075b70-c517-478a-f3bc-21a88292eb0e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbanfizsombor1999\u001b[0m (\u001b[33mgct634\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240607_154403-yf88uz5j</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gct634/Noisy%20Lyrics%20Transcription/runs/yf88uz5j' target=\"_blank\">whisper-medium-finetuned-jamendo-snr-3</a></strong> to <a href='https://wandb.ai/gct634/Noisy%20Lyrics%20Transcription' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gct634/Noisy%20Lyrics%20Transcription' target=\"_blank\">https://wandb.ai/gct634/Noisy%20Lyrics%20Transcription</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gct634/Noisy%20Lyrics%20Transcription/runs/yf88uz5j' target=\"_blank\">https://wandb.ai/gct634/Noisy%20Lyrics%20Transcription/runs/yf88uz5j</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/gct634/Noisy%20Lyrics%20Transcription/runs/yf88uz5j?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7bb1ed1b0d90>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(entity = \"gct634\", project = \"Noisy Lyrics Transcription\", name = OUTPUT_DIR\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fndcnOHFz-C0",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "fndcnOHFz-C0",
        "outputId": "fd64c2ca-2507-4ff4-e642-6fea354f2050"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAINING IN PROGRESS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='142' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 142/1100 29:50 < 3:24:11, 0.08 it/s, Epoch 6.41/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.909200</td>\n",
              "      <td>1.329445</td>\n",
              "      <td>62.711864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.034200</td>\n",
              "      <td>0.977458</td>\n",
              "      <td>99.623352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.588300</td>\n",
              "      <td>0.609203</td>\n",
              "      <td>59.039548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.310900</td>\n",
              "      <td>0.612788</td>\n",
              "      <td>49.435028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.218900</td>\n",
              "      <td>0.733746</td>\n",
              "      <td>33.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.181100</td>\n",
              "      <td>0.584338</td>\n",
              "      <td>30.131827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# processor.save_pretrained(training_args.output_dir)\n",
        "\n",
        "trainer.add_callback(progress_callback)\n",
        "trainer.add_callback(early_stopping)\n",
        "print('TRAINING IN PROGRESS...')\n",
        "\n",
        "trainer.train()\n",
        "print('DONE TRAINING')\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8wf_8Gzy6R9i",
      "metadata": {
        "id": "8wf_8Gzy6R9i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}